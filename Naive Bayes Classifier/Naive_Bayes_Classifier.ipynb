{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Data Mining Task 1\n",
    "I follow this links when i write this code.\n",
    "Sources: <br>\n",
    "1-) https://medium.com/@abhishek.km23/naive-bayes-classifier-calculation-of-prior-likelihood-evidence-posterior-74d7d27eec24 <br>\n",
    "2-) https://www.geeksforgeeks.org/ml-naive-bayes-scratch-implementation-using-python/ <br>\n",
    "3-) https://scikit-learn.org/stable/modules/naive_bayes.html <br>\n",
    "4-) https://gist.github.com/tuttelikz/94f750ef3bf14f8a126a <br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Ä°mport required libraries and read dataset from cvs file "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   region  tenure  age  marital  address  income  ed  employ  retire  gender  \\\n",
       "0       2      13   44        1        9    64.0   4       5     0.0       0   \n",
       "1       3      11   33        1        7   136.0   5       5     0.0       0   \n",
       "2       3      68   52        1       24   116.0   1      29     0.0       1   \n",
       "\n",
       "   reside  custcat  \n",
       "0       2        1  \n",
       "1       6        4  \n",
       "2       2        3  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region</th>\n      <th>tenure</th>\n      <th>age</th>\n      <th>marital</th>\n      <th>address</th>\n      <th>income</th>\n      <th>ed</th>\n      <th>employ</th>\n      <th>retire</th>\n      <th>gender</th>\n      <th>reside</th>\n      <th>custcat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>13</td>\n      <td>44</td>\n      <td>1</td>\n      <td>9</td>\n      <td>64.0</td>\n      <td>4</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>11</td>\n      <td>33</td>\n      <td>1</td>\n      <td>7</td>\n      <td>136.0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>68</td>\n      <td>52</td>\n      <td>1</td>\n      <td>24</td>\n      <td>116.0</td>\n      <td>1</td>\n      <td>29</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 233
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np # using dataframe as list of lists\n",
    "import pandas as pd # reading csv and translate it to dataframe \n",
    "import math # for sqrt, pi and exp steps\n",
    "import random  # for creating randomization when spliting data to train and test\n",
    "\n",
    "df = pd.read_csv('teleCust1000t.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "source": [
    "### Drop (or delete) the columns that we will not use. Keep only numerical values and class labels. We can drop the colums or transfer only the columns that we will use to dataset list."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "metadata": {},
     "execution_count": 234
    }
   ],
   "source": [
    "# another method -------------------------------------------------------------------------\n",
    "#                                                                                        |\n",
    "# df = df.drop(['region','marital', 'address', 'ed', 'retire', 'gender', 'reside'],1) <--- \n",
    "dataset = df[['tenure','age','income','employ','custcat']].values\n",
    "type(dataset)\n",
    "# we have a list that every element of list have one row from our dataset.csv file."
   ]
  },
  {
   "source": [
    "### Split the dataset for train and test data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(datataset, ratio):\n",
    "    sizeoftrain = int(len(dataset)*ratio) # get size of total dataset and calculate size of train data size with the ratio(value for splitting)\n",
    "    trainDataset = [] # create new list for train dataset\n",
    "    copyDataset = list(dataset) # get copy of original dataset\n",
    "    while len(trainDataset) < sizeoftrain:\n",
    "        x = random.randrange(len(copyDataset)) # select random row of dataset\n",
    "        trainDataset.append(copyDataset.pop(x)) # move selected row to train dataset\n",
    "    return [trainDataset, copyDataset] # return train and test set"
   ]
  },
  {
   "source": [
    "### Calculate probability of likelihood (P(Xi | Label))"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://wikimedia.org/api/rest_v1/media/math/render/svg/685339e22f57b18d804f2e0a9c507421da59e2ab  <--- formula\n",
    "# we dont use pow(stddev,2) on first part of formula because it will become a stdDev in sqrt function\n",
    "def calculateLikelihood(x,mean,stdDev):\n",
    "    exponent = math.exp(-(math.pow(x - mean,2)/2*math.pow(stdDev,2)))\n",
    "    result = 1/(math.sqrt(2*math.pi)*stdDev)*exponent\n",
    "    return result"
   ]
  },
  {
   "source": [
    "### Seperate the dataset by classes and store them in dictionary"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateByClass(dataset):\n",
    "    classDataDict = {} # create dictionary for store classes and their instances {label1:rows, label2:rows ...}\n",
    "    for i in range(len(dataset)):\n",
    "        current = dataset[i] # get the current row to \"current\" variable\n",
    "        if current[-1] not in classDataDict: # if the current row's class label not seen before, create new list for it\n",
    "            classDataDict[current[-1]] = []\n",
    "        classDataDict[current[-1]].append(current) # append row (instance) to their class labels list on dictionary \n",
    "    return classDataDict"
   ]
  },
  {
   "source": [
    "### Get every class label's instances mean and standart deviations of every columns(features)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanAndStddevs(dataset):\n",
    "\tsummaries = [(np.mean(attribute), np.std(attribute)) for attribute in zip(*dataset)] # zip(*list) function unpack elements in list and use them\n",
    "    # https://stackoverflow.com/questions/29139350/difference-between-ziplist-and-ziplist    <-- source\n",
    "\tdel summaries[-1] # we delete the last element of list because its the mean and stdDev of our class labels and we will not use this values\n",
    "\treturn summaries"
   ]
  },
  {
   "source": [
    "### Calculate mean and stdDev for every class label"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanAndStddevPerClass(dataset):\n",
    "    seperated = separateByClass(dataset) # get seperated by class dictionary \n",
    "    result = {}\n",
    "    for label, instances in seperated.items(): # calculate mean and stdDev of instances per Class and store them on dict\n",
    "        result[label] = meanAndStddevs(instances)\n",
    "    return result"
   ]
  },
  {
   "source": [
    "### Calculate probabilities of test input and find the best probability(and use it as result)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(meanAndStddevData, inputData):  # https://www.saedsayad.com/images/Bayes_rule.png\n",
    "    probabilities = {}\n",
    "    for label, meanandstdDev in meanAndStddevData.items():\n",
    "        probabilities[label] = 1\n",
    "        for i in range(len(meanandstdDev)): # loop run for every column of instances and use the mean and stdDev values of this columns for this class labels\n",
    "            x = inputData[i]\n",
    "            mean, stdev = meanandstdDev[i]\n",
    "            probabilities[label] *= calculateLikelihood(x,mean,stdev) \n",
    "            # we dont calculate P(C) as (number of C/ total) because every calculation \"total\" is constant and dont effect our calculation\n",
    "\n",
    "    bestlabel = None\n",
    "    bestProb = -1\n",
    "    for labels, probability in probabilities.items():\n",
    "        if bestlabel is None or bestProb < probability:\n",
    "            bestProb = probability\n",
    "            bestlabel = labels\n",
    "    return bestlabel"
   ]
  },
  {
   "source": [
    "### Get test sample and calculate accuracy value"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(meanAndStddevData, testSet):\n",
    "\tpredictions = []\n",
    "\tfor i in range(len(testSet)):\n",
    "\t\tresult = predict(meanAndStddevData, testSet[i])\n",
    "\t\tpredictions.append(result) # \"prediction\" list have the class labels that predicted \n",
    "\treturn predictions\n",
    "\n",
    "\n",
    "def getAccuracy(testSet, predictions):\n",
    "\tcorrect = 0\n",
    "\tfor x in range(len(testSet)):\n",
    "\t\tif testSet[x][-1] == predictions[x]: # if prediction is true on dataset, increase correct answer counter\n",
    "\t\t\tcorrect += 1\n",
    "\tresult = (correct/float(len(testSet)))*100.0\n",
    "\treturn result"
   ]
  },
  {
   "source": [
    "### Test the naive bayes implementation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ratio = 0.80\n",
    "    trainingSet, testSet = split(dataset, ratio)\n",
    "    print('Size of dataset: ', len(dataset), '\\nTrain dataset size:', len(trainingSet), '\\nTest dataset size: ', len(testSet))\n",
    "    meanAndStdDevdata = meanAndStddevPerClass(trainingSet)\n",
    "    predictions = getPredictions(meanAndStdDevdata, testSet)\n",
    "    accuracy = getAccuracy(testSet, predictions)\n",
    "    print('Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Size of dataset:  1000 \nTrain dataset size: 800 \nTest dataset size:  200\nAccuracy:  25.5\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "source": [
    "### The accuracy value can change every run because of the random selection on dataset splitting and also the ratio effect the accuracy.\n",
    "\n",
    "Some results that i got:\n",
    "Ratio: 0.75     %26.8 <br>\n",
    "Ratio: 0.8      %27.0 <br>\n",
    "Ratio: 0.85     %30.0 <br>\n",
    "Ratio: 0.9      %28.9 <br>\n",
    "Ratio: 0.85     %34.0 <br>\n",
    "\n",
    "This values can be change on every run."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}